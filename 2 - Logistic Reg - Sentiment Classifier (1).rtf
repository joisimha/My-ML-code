{\rtf1\ansi\ansicpg1252\deff0{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red0\green0\blue0;\red192\green80\blue77;\red0\green176\blue80;\red255\green0\blue255;\red204\green204\blue204;}
{\*\generator Msftedit 5.41.21.2512;}\viewkind5\uc1{\*\background{\shp{\*\shpinst
{\sp{\sn fillType}{\sv 0}}
{\sp{\sn fillBackColor}{\sv 0}}
{\sp{\sn fillFocus}{\sv 0}}
{\sp{\sn fillBlip}{\sv {\pict\wmetafile0\picscalex1\picscaley1 
}}}}}}
\pard\sl240\slmult1\cf1\lang9\ul\b\f0\fs36 # Sentiment Classifier (Log Reg)\fs24\par
\par
\par
# Data and feature review\par
\ulnone\b0 import graphlab as gl\par
\par
# Read product review data for Amazon baby products\par
products = gl.SFrame('amazon_baby.gl')\par
\b\par
\b0 # Explore by reading first few lines of review using head() cmd \par
products.head()\par
\par
\b # Remove \ul all\ulnone  punctuations from reviews \b0\par
def remove_punctuation(text):\par
    import string\par
    return text.translate(None, string.punctuation) \par
\par
review_without_puctuation = products['review'].apply(remove_punctuation)\par
products['word_count'] = gl.text_analytics.count_words(review_without_puctuation)\par
\b\par
\par
# Build word count vector for each review (with punctuations)\par
\b0\i # This adds a column in the data set to count number of words. It scans the words in "REVIEW" column and puts it as a dictionary listing in the "WORD COUNT" column. Use count_words() func. Bigrams and Trigrams are also available in the text analytics toolbox.\par
\i0\par
products['word_count'] = gl.text_analytics.count_words(products['review'])\par
\par
# Set canvas to Python notebook so graphs show in current notebook \par
gl.canvas.set_target('ipynb')\par
\par
# Visualize the products by pareto list using show() command\par
products['name'].show()\par
\b\par
\b0 # Explore the most popular product\par
# Assign a specific product data in a variable by assignment\par
giraffe_reviews = products[products['name' == 'Vulli Sophie the Giraffe Teether']]\par
\b\par
\b0 # How many reviews?\par
length(giraffe_reviews) \par
\b\par
\b0 # Look at the ratings for this highest rated product in a Categorical view\par
giraffe_reviews['rating'].show(view='Categorical')\par
\par
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\par
\ul\par
\b # 1) Building a wordcount based classifier model\ulnone  (simple_model)\par
\b0 # Based on the word count we are going to predict their rating. \par
\b\par
\b0 # Label reviews as 0 and 1 instead of 1 to 5 scale. This gives us a single class classification problem. Define a +ve and -ve sentiment. Ignore all 3* reviews for training since they are on the border and do not tell us much about good vs. bad\b\par
\b0\par
products = products[products['rating'] !=3]\par
\par
# A positive sentiment is a 4* or 5* review. Add a sentiment column and assign 1 if rating is >=4 and 0 if rating is <4. This converts a multi-class problem into a single class problem!\par
\b\par
\b0 products['sentiment'] = products['rating'] >= 4 \par
\cf2\par
# Alternative way of extracting sentiments into single class\par
# products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else 0)\par
\cf1\par
products.head()\par
\ul\b\par
# Training a simple word count classifier\par
\ulnone\b0\par
# Split the data set into train (80%) and test (20%)\par
train_data, test_data = products.random_split(0.8, seed =0)\par
\b\par
\b0 # First step is to learn theta using word count\par
\b\par
# Call built-in logistic_classifier function with arguements: dataset, target variable h(x), features X and if there is a validation set to evaluate training set theta\par
\b0\par
\cf3\b simple_model = gl.logistic_classifier.create(train_data, target='sentiment', features = ['word_count'], validation_set=test_data)\par
\par
\par
\cf0 # Coefficients - Load fitted coefficients in weights vector. Column names are the corresponding features\par
\b0 weights = simple_model.coefficients\par
weights.column_names()\par
\par
# Number of positive and negative feature weights in the fitted model \par
num_pos_weights = len(weights[weights['value'] >= 0)]\par
num_neg_weights = len(weights[weights['value'] <0)]\par
\cf3\b\par
\par
\cf1\ul # Evaluating the classifier\b0\par
\ulnone # Using ROC curve / Confusion matrix\b\par
\b0 simple_model.evaluate(test_data, metric='roc_curve')\par
\par
# Visualize the ROC curve \par
simple_model.show(view='Evaluation')\par
\par
# Build my own Matthews Correlation Coefficient function\par
# How to get values from evaluate?\par
\b\par
# Apply the learned classifier to see how it did on a few data points of the Giraffe product\b0 . Get predicted output in terms of probabilities instead of 1 and 0 to understand classifier confidence \par
\b\par
\b0 giraffe_reviews['predicted_sentiment'] = simple_model.\highlight4 predict\highlight0 (giraffe_reviews, output_type='probability')\par
giraffe_reviews.head()\par
\par
# Sort reviews based on the predicted sentiment (desc order of predicted values)\b\par
\b0 giraffe_reviews = giraffe_reviews.sort('predicted sentiment', ascending=0)\par
\par
# Explore extreme positive reviews (start at 0, 1...) \b\par
\b0 giraffe_reviews[0]['review']\par
giraffe_reviews[1]['review']\par
\par
# Explore extreme negative reviews (start at -1, -2...)\par
giraffe_reviews[-1]['review']\par
giraffe_reviews[-2]['review']\par
\b\par
\par
\b0 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\par
\ul\b # 2) Building a subset of word count to classify data\ulnone\par
\par
\par
\par
\b0 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\par
\ul\b # 3) Building a classifier with selected words as features\par
\ulnone\b0\par
products['word_count'] = gl.text_analytics.count_words(products['review'])\par
\par
selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', 'terrible', 'awful', 'wow', 'hate']\par
length = len(selected_words)\par
\par
\lang1033\b # Counting number of times a selected word appears in the review and apply for all reviews\b0\par
def sel_word_count(cell):\par
    if 'awesome' in cell:\par
        return cell['awesome']\par
    else:\par
        return 0\par
products['awesome'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'great' in cell:\par
        return cell['great']\par
    else:\par
        return 0\par
products['great'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'fantastic' in cell:\par
        return cell['fantastic']\par
    else:\par
        return 0\par
products['fantastic'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'amazing' in cell:\par
        return cell['amazing']\par
    else:\par
        return 0\par
products['amazing'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'love' in cell:\par
        return cell['love']\par
    else:\par
        return 0\par
products['love'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'horrible' in cell:\par
        return cell['horrible']\par
    else:\par
        return 0\par
products['horrible'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'bad' in cell:\par
        return cell['bad']\par
    else:\par
        return 0\par
products['bad'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'terrible' in cell:\par
        return cell['terrible']\par
    else:\par
        return 0\par
products['terrible'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'awful' in cell:\par
        return cell['awful']\par
    else:\par
        return 0\par
products['awful'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'wow' in cell:\par
        return cell['wow']\par
    else:\par
        return 0\par
products['wow'] = products['word_count'].apply(sel_word_count)\par
\par
def sel_word_count(cell):\par
    if 'hate' in cell:\par
        return cell['hate']\par
    else:\par
        return 0\par
products['hate'] = products['word_count'].apply(sel_word_count)\par
\par
\par
# To sum individual column feature counts\par
products['awesome'].sum()\par
\par
\par
\b # Training parameters with selected word features\par
\b0\par
train_data, test_data = products.random_split(0.8, seed=0)\par
\par
\cf3\b selected_words_model= gl.logistic_classifier.create(train_data, target='sentiment', features = selected_words,validation_set=test_data)\par
\lang9\par
\cf0 # See how the model has parameterized each adjective as described by raters\par
\b0 selected_words_model['coefficients']\par
selected_words_model['coefficients'].sort('value')\cf5\par
\par
\cf0\b # Evaluation the 2 models\cf5\b0\par
\cf0 simple_model.evaluate(test_data)\par
selected_words_model.evaluate(test_data)\par
\cf5\par
\par
\cf0 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\par
\b # Classification Accuracy based on confusion table entries\par
\b0 # Accuracy, F1 Score and Mathews Correlation Coefficient\par
\par
def evaluation_metrics(tn, fp, tp, fn):\par
\tab tn = float(tn)\par
\tab fp = float(fp)\par
\tab tp = float(tp)\par
\tab fn = float(fn)\par
\par
\tab accuracy = (tp+tn)/((tp+fn)+(fp+tn))\par
\tab f1 = (2*tp)/(2*tp+ fp + fn)\par
\tab mcc = ((tp * tn) - (fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**(1/2.0)\par
\par
\tab print "Accuracy = ", accuracy\par
\tab print "F1 Score =", f1\par
\tab print "MCC = ", mcc\par
\par
\par
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\par
\par
}
 